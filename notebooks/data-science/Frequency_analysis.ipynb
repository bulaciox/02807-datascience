{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d78c8fc9",
   "metadata": {},
   "source": [
    "This first part is used to create the binary encoding out of the data. It reads the cluster data along with aggregated data and goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9f8127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../../data/interim/player_season_stats_23-24_relevant.csv\")\n",
    "goal_data = pd.read_csv('../../data/interim/player_season_stats_23-24.csv', sep=',', encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5477eb35",
   "metadata": {},
   "source": [
    "Aggregating the fines and storing them as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ebd8623",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_goals = goal_data.groupby('player', as_index=False).agg({\n",
    "    'Gls': 'sum',    # sum goals\n",
    "    'Ast': 'sum',    # sum assists\n",
    "    'player': 'first'  # keep the first occurrence of Name\n",
    "})\n",
    "\n",
    "#Save aggregated goals to a new csv file\n",
    "aggregated_goals.to_csv('../../data/processed/aggregated_goals.csv', index=False)\n",
    "\n",
    "#Aggregate data by player\n",
    "categorical_cols = ['league', 'season',\t'team',\t'player', 'nation',\t'pos',\t'age']\n",
    "\n",
    "sum_numeric_cols = ['MP Playing Time', 'Min Playing Time', 'KP',\t'PrgP',\t'PPA',\t'CrsPA', 'Att Long', 'TB Pass Types', 'Sw Pass Types', 'Crs Pass Types', 'PrgC Carries', 'CPA Carries',\t'Succ Take-Ons',    'Dis Carries',\t'Mis Carries',\t'PrgR Receiving', 'TklW Tackles', 'Att 3rd Tackles', 'Mid 3rd Tackles',\t'Def 3rd Tackles',\t'Int',\t'Sh Blocks', 'Recov Performance', 'Won Aerial Duels', 'Fls Performance', 'Fld Performance', 'Att Pen Touches', 'Att 3rd Touches', 'Mid 3rd Touches', 'Def 3rd Touches',\t'Def Pen Touches', 'Live Touches',\t'Cmp Total']\n",
    "average_cols = ['90s Playing Time',\t'npxG Per 90 Minutes',\t'G-PK Per 90 Minutes',\t'xAG Per 90 Minutes',\t'xG+xAG Per 90 Minutes',\t'Sh/90 Standard',\t'SoT% Standard',\t'Dist Standard',\t'G/Sh Standard',\t'Cmp% Total',\t'Cmp% Long',\t'Succ% Take-Ons', 'Won% Aerial Duels']\n",
    "\n",
    "aggregated_data = data.groupby('player', as_index=False).agg({\n",
    "    **{col: 'first' for col in categorical_cols},  # keep the first occurrence of categorical columns\n",
    "    **{col: 'sum' for col in sum_numeric_cols},        # sum numeric columns\n",
    "    **{col: 'mean' for col in average_cols}        # average specified columns \n",
    "})\n",
    "\n",
    "#save aggregated data to a new csv file\n",
    "aggregated_data.to_csv('../../data/processed/aggregated_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966d447e",
   "metadata": {},
   "source": [
    "Read the cluster data and merge everything for binary encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fe5021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('../../data/processed/aggregated_data.csv', sep=',', encoding=\"latin1\")\n",
    "clustered_data = pd.read_csv('../../data/processed/players_w_clusters.csv', sep=',', encoding=\"latin1\")\n",
    "goal_data = pd.read_csv('../../data/processed/aggregated_goals.csv', sep=',', encoding=\"latin1\")\n",
    "\n",
    "# Merge cluster labels by player name\n",
    "data = data.merge(clustered_data[['player', 'cluster']], on='player', how='left')\n",
    "cols = list(data.columns)\n",
    "# Remove cluster and reinsert at index 2\n",
    "cols.insert(2, cols.pop(cols.index('cluster')))\n",
    "# Reorder dataframe\n",
    "data = data[cols]\n",
    "\n",
    "# Merge goals and assists by player name\n",
    "data = data.merge(goal_data[['player', 'Gls']], on='player', how='left')\n",
    "data = data.merge(goal_data[['player', 'Ast']], on='player', how='left')\n",
    "\n",
    "#Store the headers in a list\n",
    "headers = data.columns.tolist()\n",
    "filtered_data = data.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc084015",
   "metadata": {},
   "source": [
    "Data manipulation to only take big group clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e9672c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: 0.0, Number of players: 581\n",
      "Cluster: 4.0, Number of players: 346\n",
      "Cluster: 5.0, Number of players: 801\n",
      "Cluster: 8.0, Number of players: 286\n",
      "Cluster: 9.0, Number of players: 242\n",
      "Cluster: 16.0, Number of players: 105\n"
     ]
    }
   ],
   "source": [
    "#Group the data by cluster\n",
    "clustered_grouped_data = filtered_data.groupby('cluster')\n",
    "\n",
    "#Remove clusters with less than 50 from filtered data\n",
    "cluster_sizes = clustered_grouped_data.size()\n",
    "clusters_to_keep = cluster_sizes[cluster_sizes >= 50].index\n",
    "filtered_data = filtered_data[filtered_data['cluster'].isin(clusters_to_keep)]\n",
    "\n",
    "#Group the data by cluster\n",
    "clustered_grouped_data = filtered_data.groupby('cluster')\n",
    "\n",
    "#Print the number of players in each cluster \n",
    "for cluster, group in clustered_grouped_data:\n",
    "    num_players = len(group)\n",
    "    print(f\"Cluster: {cluster}, Number of players: {num_players}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31b5ccd",
   "metadata": {},
   "source": [
    "Transform into binary encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f12bb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the 90th percentile for each stat in each cluster\n",
    "stats = headers[8:]\n",
    "result = {}\n",
    "\n",
    "# Loop through clusters and stats\n",
    "for cluster, group in clustered_grouped_data:\n",
    "    result[cluster] = {}\n",
    "    for stat in stats:\n",
    "        result[cluster][stat] = group[stat].quantile(0.90)\n",
    "\n",
    "#Transform data into binary format based on 90th percentile\n",
    "binary_data = filtered_data.copy()\n",
    "for cluster in result:\n",
    "    for stat in stats:\n",
    "        threshold = result[cluster][stat]\n",
    "        binary_data.loc[binary_data['cluster'] == cluster, stat] = binary_data.loc[binary_data['cluster'] == cluster, stat].apply(lambda x: 1 if x >= threshold else 0)\n",
    "\n",
    "#Save the binary data to a new CSV file\n",
    "binary_data.to_csv('../../data/processed/binary_encoded_player_stats_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18141bba",
   "metadata": {},
   "source": [
    "Import libraries for Analysis and read code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65c7cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "bin_data = pd.read_csv('../../data/processed/binary_encoded_player_stats_2.csv', sep=',', encoding=\"latin1\")\n",
    "\n",
    "# Dictionary to store cluster-wise stat metrics\n",
    "cluster_stats = {'cluster': [], 'stat': [], 'lift': [], 'confidence': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88ff8a1",
   "metadata": {},
   "source": [
    "Calculate Dynamic Support "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eaf549cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by cluster\n",
    "clustered = bin_data.groupby('cluster')\n",
    "\n",
    "# Function to calculate dynamic min_support\n",
    "def compute_dynamic_support(cluster_size):\n",
    "    return max(0.03, 5 / cluster_size)\n",
    "\n",
    "# Dictionary to store min_support per cluster\n",
    "dynamic_supports = {}\n",
    "\n",
    "for cluster, group in clustered:\n",
    "    size = len(group)\n",
    "    gls_count = group['Gls'].sum()\n",
    "    goal_rate = gls_count / size\n",
    "    min_sup = compute_dynamic_support(size)\n",
    "    dynamic_supports[cluster] = min_sup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db641d1",
   "metadata": {},
   "source": [
    "APRIORI algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0095b2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------- CLUSTER 0.0 -------\n",
      "No meaningful goal-predicting single-stat rules found in this cluster.\n",
      "\n",
      "------- CLUSTER 4.0 -------\n",
      "No meaningful goal-predicting single-stat rules found in this cluster.\n",
      "\n",
      "------- CLUSTER 5.0 -------\n",
      "No meaningful goal-predicting single-stat rules found in this cluster.\n",
      "\n",
      "------- CLUSTER 8.0 -------\n",
      "No meaningful goal-predicting single-stat rules found in this cluster.\n",
      "\n",
      "------- CLUSTER 9.0 -------\n",
      "No meaningful goal-predicting single-stat rules found in this cluster.\n",
      "\n",
      "------- CLUSTER 16.0 -------\n",
      "No meaningful goal-predicting single-stat rules found in this cluster.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\praga\\Miniconda3\\envs\\dtu02450\\Lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "c:\\Users\\praga\\Miniconda3\\envs\\dtu02450\\Lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "c:\\Users\\praga\\Miniconda3\\envs\\dtu02450\\Lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "c:\\Users\\praga\\Miniconda3\\envs\\dtu02450\\Lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "c:\\Users\\praga\\Miniconda3\\envs\\dtu02450\\Lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n",
      "c:\\Users\\praga\\Miniconda3\\envs\\dtu02450\\Lib\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for cluster, group in clustered:\n",
    "\n",
    "    if group['Gls'].mean() == 1:\n",
    "        print(f\"\\nSkipping Cluster {cluster} â€” all players have Gls=1.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n------- CLUSTER {cluster} -------\")\n",
    "\n",
    "    cluster_data = group.drop(columns=[\n",
    "        'cluster','league','player','season',\n",
    "        'team','nation','pos','age'\n",
    "    ])\n",
    "    support_threshold = dynamic_supports[cluster]\n",
    "\n",
    "    # Apriori (must allow 2-item sets!)\n",
    "    frequent_itemsets = apriori(\n",
    "        cluster_data,\n",
    "        min_support=support_threshold,\n",
    "        use_colnames=True,\n",
    "        max_len=2\n",
    "    )\n",
    "\n",
    "    # Association rules\n",
    "    rules = association_rules(\n",
    "        frequent_itemsets,\n",
    "        metric=\"confidence\",\n",
    "        min_threshold=0.3\n",
    "    )\n",
    "\n",
    "    if rules.empty:\n",
    "        print(\"No rules generated for this cluster.\")\n",
    "        continue\n",
    "\n",
    "    # Remove rules with lift < 1\n",
    "    rules = rules[rules['lift'] >= 1]\n",
    "\n",
    "    if rules.empty:\n",
    "        print(\"No rules with lift >= 1.\")\n",
    "        continue\n",
    "\n",
    "    # Keep only rules where consequent == {Gls}\n",
    "    rules_to_goals = rules[\n",
    "        rules['consequents'].apply(lambda x: len(x) == 1 and 'Gls' in x)\n",
    "    ]\n",
    "\n",
    "    if rules_to_goals.empty:\n",
    "        print(\"No rules implying Gls.\")\n",
    "        continue\n",
    "\n",
    "    # Keep only single-stat antecedents\n",
    "    rules_to_goals = rules_to_goals[\n",
    "        rules_to_goals['antecedents'].apply(lambda a: len(a) == 1)\n",
    "    ]\n",
    "\n",
    "    if rules_to_goals.empty:\n",
    "        print(\"No single-stat rules implying Gls.\")\n",
    "        continue\n",
    "\n",
    "    # Store\n",
    "    for _, row in rules_to_goals.iterrows():\n",
    "        stat = list(row['antecedents'])[0]\n",
    "        cluster_stats['cluster'].append(cluster)\n",
    "        cluster_stats['stat'].append(stat)\n",
    "        cluster_stats['lift'].append(row['lift'])\n",
    "        cluster_stats['confidence'].append(row['confidence'])\n",
    "\n",
    "    print(\"\\nSingle-stat rules implying goals:\")\n",
    "    print(rules_to_goals[['antecedents','consequents','support','confidence','lift']])\n",
    "\n",
    "    # Ranking\n",
    "    stats = [list(a)[0] for a in rules_to_goals['antecedents']]\n",
    "    lifts = rules_to_goals['lift'].tolist()\n",
    "    lift_df = pd.DataFrame({'stat': stats, 'lift': lifts})\n",
    "    lift_df = lift_df.groupby('stat').sum().sort_values('lift', ascending=False)\n",
    "\n",
    "    print(\"\\nStats ranked by lift (single-stat influence):\")\n",
    "    print(lift_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b48a22",
   "metadata": {},
   "source": [
    "Visuialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb160d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for cluster-wise stat metrics\n",
    "cluster_stats_df = pd.DataFrame(cluster_stats)\n",
    "\n",
    "#Display table where each row is a cluster and each column is a st\n",
    "pivot_table = cluster_stats_df.pivot(index='cluster', columns='stat', values='lift').fillna(0)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(pivot_table, annot=True, cmap=\"YlGnBu\", square=True, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title(\"Heatmap of Stat Influence (Lift) by Cluster\")\n",
    "plt.xlabel(\"Stat\")\n",
    "plt.ylabel(\"Cluster\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtu02450",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
